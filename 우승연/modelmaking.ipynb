{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 만들기 <hr>\n",
    "\n",
    "- CNN 모델 전이학습: Mobilenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모듈 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리/ Resizing, Tensorize\n",
    "preprocessing = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더명 = 분류 클래스\n",
    "root = 'TrashType_Image_Dataset'\n",
    "dataset = ImageFolder(root = root, transform= preprocessing) #전처리\n",
    "loader = DataLoader(dataset = dataset, batch_size=32, shuffle=False) #dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kdp\\anaconda3\\envs\\NLP_38\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kdp\\anaconda3\\envs\\NLP_38\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# mobilenet model\n",
    "\n",
    "model = models.mobilenet_v2(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(nn.Dropout(0.2),\n",
    "                                  nn.Linear(num_features, 1),# 이진분류니까 출력 노드는 한 개\n",
    "                                  nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer, 손실함수 정의하기\n",
    "\n",
    "creterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH] 1 / 150\n",
      "\n",
      "[LOSS] : 0.6954\n",
      "[EPOCH] 2 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 3 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 4 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 5 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 6 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 7 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 8 / 150\n",
      "\n",
      "[LOSS] : 0.6455\n",
      "[EPOCH] 9 / 150\n",
      "\n",
      "[LOSS] : 0.7341\n",
      "[EPOCH] 10 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 11 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 12 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 13 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 14 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 15 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 16 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 17 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 18 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 19 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 20 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 21 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 22 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 23 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 24 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 25 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 26 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 27 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 28 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 29 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 30 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 31 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 32 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 33 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 34 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 35 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 36 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 37 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 38 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 39 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 40 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 41 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 42 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 43 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 44 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 45 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 46 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 47 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 48 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 49 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 50 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 51 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 52 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 53 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 54 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 55 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 56 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 57 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 58 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 59 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 60 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 61 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 62 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 63 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 64 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 65 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 66 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 67 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 68 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 69 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 70 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 71 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 72 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 73 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 74 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 75 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 76 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 77 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 78 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 79 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 80 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 81 / 150\n",
      "\n",
      "[LOSS] : 0.6931\n",
      "[EPOCH] 82 / 150\n",
      "\n",
      "[LOSS] : 0.6731\n",
      "[EPOCH] 83 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 84 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 85 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 86 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 87 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 88 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 89 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 90 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 91 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 92 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 93 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 94 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 95 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 96 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 97 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 98 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 99 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 100 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 101 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 102 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 103 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 104 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 105 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 106 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 107 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 108 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 109 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 110 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 111 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 112 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 113 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 114 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 115 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 116 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 117 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 118 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 119 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 120 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 121 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 122 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 123 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 124 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 125 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 126 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 127 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 128 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 129 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 130 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 131 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 132 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 133 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 134 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 135 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 136 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 137 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 138 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 139 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 140 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 141 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 142 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 143 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 144 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 145 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 146 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 147 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 148 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 149 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n",
      "[EPOCH] 150 / 150\n",
      "\n",
      "[LOSS] : 0.7844\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "num_epochs = 150\n",
    "for ep in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = creterion(outputs, labels.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    print(f'[EPOCH] {ep+1} / {num_epochs}\\n\\n[LOSS] : {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 52.88%\n",
      "ROC_AUC 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2076\n",
      "           1       0.53      1.00      0.69      2330\n",
      "\n",
      "    accuracy                           0.53      4406\n",
      "   macro avg       0.26      0.50      0.35      4406\n",
      "weighted avg       0.28      0.53      0.37      4406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kdp\\anaconda3\\envs\\NLP_38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\kdp\\anaconda3\\envs\\NLP_38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\kdp\\anaconda3\\envs\\NLP_38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "true_labels = []\n",
    "pred_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        #model evaluation\n",
    "        outputs = model(inputs).squeeze()\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float() # 확률 기반 이진분류\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "preds = (np.array(pred_probs) > 0.5).astype(int)\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(true_labels, preds)\n",
    "print(f'Acc: {accuracy * 100:.2f}%')\n",
    "\n",
    "#roc auc 계산\n",
    "auc = roc_auc_score(true_labels, preds)\n",
    "print(f'ROC_AUC {auc:.4f}')\n",
    "\n",
    "#classification report\n",
    "print(classification_report(true_labels, preds, target_names=['0','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'Model2.pth' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
